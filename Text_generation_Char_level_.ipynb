{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation Char level .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNxQ/soiHi3Gwk6ss/0CXG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhilaksh1498/SoC-20-Chatbot/blob/master/Text_generation_Char_level_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1bcdZJqJHGw",
        "colab_type": "code",
        "outputId": "0a5d6f0d-38ff-4d43-a797-735b7678ac54",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ffa1b8af-b779-4b5c-a4d7-88d450318c35\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-ffa1b8af-b779-4b5c-a4d7-88d450318c35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"abhilakshmaheshwari\",\"key\":\"b4131928857e3bb171320644901f7a27\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6fEk8y0IKil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g1dagK1pTOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! mkdir kaggle_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wna2IyA7JkfR",
        "colab_type": "code",
        "outputId": "3f8bde81-8c94-491e-9987-7948a179ea23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# We'll use Shakespeare plays text from kaggle\n",
        "!kaggle datasets download -d kingburrito666/shakespeare-plays -p /content/kaggle_dataset"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading shakespeare-plays.zip to /content/kaggle_dataset\n",
            "\r  0% 0.00/4.55M [00:00<?, ?B/s]\r100% 4.55M/4.55M [00:00<00:00, 30.7MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDMDxpefJ9A0",
        "colab_type": "code",
        "outputId": "ed7d7787-873c-4e7e-9aeb-6493fdb9e0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!unzip /content/kaggle_dataset/shakespeare-plays.zip -d /content/kaggle_dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/kaggle_dataset/shakespeare-plays.zip\n",
            "  inflating: /content/kaggle_dataset/Shakespeare_data.csv  \n",
            "  inflating: /content/kaggle_dataset/alllines.txt  \n",
            "  inflating: /content/kaggle_dataset/william-shakespeare-black-silhouette.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBL1L7MGKOiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entire_play = open(r'/content/kaggle_dataset/alllines.txt').readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMcbRQKAKiqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entire_play = [x[:-1].strip('\"') for x in entire_play]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5CMge3dMbTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entire_play = '\\n'.join(entire_play)\n",
        "entire_play = entire_play.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfdLcMkzOUUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll implement character level since one-hot encoding of tokens may cause memory error\n",
        "# instead our target will be individual characters\n",
        "# once we recognise that its basically a classification problem\n",
        "uniq_char = sorted(set(entire_play))\n",
        "char_index = {}\n",
        "rev_index_char = {}\n",
        "char_index = {u:i for i, u in enumerate(uniq_char)}\n",
        "rev_index_char = {i:u for i, u in enumerate(uniq_char)}\n",
        "vocab_size = len(uniq_char)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UDHW2MxPBxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(entire_play) ~ 43 lakh\n",
        "seq_length = 75\n",
        "X_train = []\n",
        "y = []\n",
        "for i in range(0,len(entire_play)- seq_length, seq_length+1):\n",
        "  X_train.append(list(entire_play[i:i+seq_length]))\n",
        "  y.append(entire_play[i+seq_length])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyHlwFoGSfN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = [char_index[x] for x in X_train[i]]\n",
        "  y[i] = char_index[y[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IdOaUFHV8ln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl8i0cexXTQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y = np.array(y)\n",
        "y = to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro8-ge6zXmHn",
        "colab_type": "code",
        "outputId": "602ccc56-173f-4cd0-ea7f-558cfc1c28b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(y.shape)\n",
        "print(X_train.shape)\n",
        "print(vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57451, 51)\n",
            "(57451, 75)\n",
            "51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzPBzatLZi5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QA3U1aGbaWy",
        "colab_type": "text"
      },
      "source": [
        "### We can notice that model is not so complex as it isn't able to provide good train accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqYgyZu4mY4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir saved_model\n",
        "checkpoint_path = '/content/saved_model'\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1, save_freq='epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuJE89MjeBsZ",
        "colab_type": "code",
        "outputId": "124c2c31-766f-4029-8e8b-eef53e0b339b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "\n",
        "LATENT_DIM = 256\n",
        "input_ = tf.keras.layers.Input(shape=( seq_length , ))\n",
        "initial_h = tf.keras.layers.Input(shape=(LATENT_DIM,))\n",
        "embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length, \n",
        "                           weights=[embeddings_matrix], trainable=False)(input_)\n",
        "gru = tf.compat.v1.keras.layers.CuDNNGRU(LATENT_DIM , recurrent_initializer='glorot_uniform', return_state= True)     # dimensionality of the output space\n",
        "rnn_output,_ = gru(embedding)\n",
        "dense = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
        "output = dense(rnn_output)\n",
        "model = tf.keras.models.Model([input_, initial_h],output)\n",
        "model.summary()\n",
        "num_epochs = 5\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 75)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 75, 50)       2550        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru (CuDNNGRU)            [(None, 256), (None, 236544      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 51)           13107       cu_dnngru[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 252,201\n",
            "Trainable params: 249,651\n",
            "Non-trainable params: 2,550\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty4Suk1eHNCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "df33a15c-b339-48d1-95b3-1ecef7545a3b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHlh3yP8OWE7",
        "colab_type": "code",
        "outputId": "0b485fe0-a1e6-4310-eb80-c07b3079c7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "z = np.zeros((len(X_train),LATENT_DIM))\n",
        "num_epochs = 20\n",
        "r = model.fit([X_train,z], y_train, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[cp_callback])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1615/1616 [============================>.] - ETA: 0s - loss: 1.6960 - accuracy: 0.4722\n",
            "Epoch 00001: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.6961 - accuracy: 0.4722 - val_loss: 1.8157 - val_accuracy: 0.4513\n",
            "Epoch 2/20\n",
            "1612/1616 [============================>.] - ETA: 0s - loss: 1.6333 - accuracy: 0.4880\n",
            "Epoch 00002: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.6337 - accuracy: 0.4878 - val_loss: 1.8143 - val_accuracy: 0.4572\n",
            "Epoch 3/20\n",
            "1612/1616 [============================>.] - ETA: 0s - loss: 1.5725 - accuracy: 0.5019\n",
            "Epoch 00003: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.5729 - accuracy: 0.5018 - val_loss: 1.7962 - val_accuracy: 0.4671\n",
            "Epoch 4/20\n",
            "1613/1616 [============================>.] - ETA: 0s - loss: 1.5100 - accuracy: 0.5169\n",
            "Epoch 00004: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.5102 - accuracy: 0.5169 - val_loss: 1.8122 - val_accuracy: 0.4671\n",
            "Epoch 5/20\n",
            "1611/1616 [============================>.] - ETA: 0s - loss: 1.4501 - accuracy: 0.5326\n",
            "Epoch 00005: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.4503 - accuracy: 0.5325 - val_loss: 1.8231 - val_accuracy: 0.4697\n",
            "Epoch 6/20\n",
            "1614/1616 [============================>.] - ETA: 0s - loss: 1.3896 - accuracy: 0.5473\n",
            "Epoch 00006: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.3896 - accuracy: 0.5474 - val_loss: 1.8491 - val_accuracy: 0.4702\n",
            "Epoch 7/20\n",
            "1610/1616 [============================>.] - ETA: 0s - loss: 1.3341 - accuracy: 0.5618\n",
            "Epoch 00007: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.3348 - accuracy: 0.5617 - val_loss: 1.8681 - val_accuracy: 0.4666\n",
            "Epoch 8/20\n",
            "1615/1616 [============================>.] - ETA: 0s - loss: 1.2741 - accuracy: 0.5771\n",
            "Epoch 00008: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.2741 - accuracy: 0.5772 - val_loss: 1.9049 - val_accuracy: 0.4575\n",
            "Epoch 9/20\n",
            "1613/1616 [============================>.] - ETA: 0s - loss: 1.2207 - accuracy: 0.5924\n",
            "Epoch 00009: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.2209 - accuracy: 0.5922 - val_loss: 1.9396 - val_accuracy: 0.4603\n",
            "Epoch 10/20\n",
            "1613/1616 [============================>.] - ETA: 0s - loss: 1.1660 - accuracy: 0.6084\n",
            "Epoch 00010: saving model to /content/saved_model\n",
            "1616/1616 [==============================] - 14s 9ms/step - loss: 1.1659 - accuracy: 0.6084 - val_loss: 1.9844 - val_accuracy: 0.4556\n",
            "Epoch 11/20\n",
            "1615/1616 [============================>.] - ETA: 0s - loss: 1.1164 - accuracy: 0.6214"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-ffacdf49e04e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLATENT_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4yipGlZqQpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate poetry\n",
        "def gen_text(num_chars = 25):\n",
        "  seed_text = input('Enter seed text: ').lower()\n",
        "  seed_text= np.array([[char_index[seed_text[0]]]])\n",
        "  # Making a sampling model\n",
        "  input_2 = tf.keras.layers.Input(shape=(1,))\n",
        "  embedding_sampling = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=seq_length, \n",
        "                                                weights=[embeddings_matrix], trainable=False)(input_2)\n",
        "  gru_output, h = gru(embedding_sampling, initial_state = [initial_h])\n",
        "  output_sampling = dense(gru_output)\n",
        "\n",
        "  sampling_model = tf.keras.models.Model(inputs = [input_2, initial_h], outputs = [output_sampling, h] )\n",
        "  play = True\n",
        "  state_h = np.zeros((1,LATENT_DIM))\n",
        "  generated_text = ''\n",
        "  while(play):\n",
        "    for _ in range(num_chars):\n",
        "      prob, state_h = sampling_model.predict([seed_text,state_h])\n",
        "      # for poetry generation instead of using greedy approach we'll sample the characters based on probability distributions\n",
        "      prob /= prob.sum() # Sum of prob = 1, (the sigmoid function ensures each entry between 0 and 1)\n",
        "      next_charIndex = np.random.choice(a = vocab_size, p = prob[0])\n",
        "      generated_text += rev_index_char[next_charIndex]\n",
        "      seed_text = np.array([[next_charIndex]]) \n",
        "    play_again = input('Do you want to generate again? (y/n)')\n",
        "    play = True if (play_again.lower()=='y') else False\n",
        "  print(generated_text)\n",
        "  return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnfxPNrs9U6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b72f046b-b3d0-42fa-ff83-92467dea381e"
      },
      "source": [
        "print(np.array([char_index['a']]).shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebcWieY03rsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "84511714-ab70-4fe2-82c1-5cf2ee007fe4"
      },
      "source": [
        "gen_text()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter seed text: H\n",
            "Do you want to generate again? (y/n)y\n",
            "Do you want to generate again? (y/n)y\n",
            "Do you want to generate again? (y/n)y\n",
            "Do you want to generate again? (y/n)n\n",
            ", trot now, but my degrez have i in that teon, then brother pandly in\n",
            "farleds\n",
            "the\n",
            "glibeus, but, apte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEwwCQ9u9Mw7",
        "colab_type": "code",
        "outputId": "acb94900-bf4e-449b-d0e3-7a7065764d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "! mkdir pre_trained_vec\n",
        "! kaggle datasets download -d rtatman/glove-global-vectors-for-word-representation -p /content/pre_trained_vec"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove-global-vectors-for-word-representation.zip to /content/pre_trained_vec\n",
            " 98% 448M/458M [00:11<00:00, 32.7MB/s]\n",
            "100% 458M/458M [00:11<00:00, 43.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpKseo-z-XB4",
        "colab_type": "code",
        "outputId": "2f91d567-ed13-489e-a0ab-a0dde92d340d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "! unzip /content/pre_trained_vec/glove-vectors.zip -d /content/pre_trained_vec\n",
        "# We'll use 50d vectors\n",
        "glove = open(r'/content/pre_trained_vec/glove.6B.50d.txt', 'r').read()\n",
        "import numpy as np\n",
        "embedding_dict = {}\n",
        "for line in glove.split('\\n')[:-1]:\n",
        "  line = line.split()\n",
        "  embedding_dict[line[0]] = np.asarray(line[1:], dtype = 'float32')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/pre_trained_vec/glove-vectors.zip\n",
            "  inflating: /content/pre_trained_vec/glove.6B.100d.txt  \n",
            "  inflating: /content/pre_trained_vec/glove.6B.200d.txt  \n",
            "  inflating: /content/pre_trained_vec/glove.6B.50d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCl85UfX9kFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 50\n",
        "embeddings_matrix = np.zeros((vocab_size, embedding_dim)); # 0th index will be padding\n",
        "not_found_chars = []\n",
        "for char,index in char_index.items():\n",
        "  vec = embedding_dict.get(char)         # if word is not present it returns None as value\n",
        "  if vec is not None:\n",
        "    embeddings_matrix[index] = vec       # words in corpus not found in glove (including oov_token) will be given 0 vector\n",
        "  else:\n",
        "    not_found_chars.append(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE2OJ1KEjyt0",
        "colab_type": "text"
      },
      "source": [
        "I'll copy the code directly and try to run it"
      ]
    }
  ]
}