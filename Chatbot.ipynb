{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMw+FznnRbZu6Tb8tfuVKJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhilaksh1498/SoC-20-Chatbot/blob/master/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbcJti_PLHUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUnrk3yRORNF",
        "colab_type": "code",
        "outputId": "1d39c89e-efd0-43d6-b65b-bc4be542d19b",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "# To check the runtime type\n",
        "import tensorflow as tf \n",
        "tf.test.gpu_device_name() \n",
        "# If GPU is connected it will display --- '/device:GPU:0'\n",
        "\n",
        "# Uploading a file\n",
        "from google.colab import files \n",
        "uploaded = files.upload() \n",
        "\n",
        "# to save it as a dataframe\n",
        "# import io \n",
        "# df2 = pd.read_csv(io.BytesIO(uploaded['file_name.csv']))\n",
        "\n",
        "# for more instructions use this link-  https://www.geeksforgeeks.org/how-to-use-google-colab/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4fa29ae1-d6b6-4c37-9421-70c8a7c76340\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4fa29ae1-d6b6-4c37-9421-70c8a7c76340\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving ai.yml to ai.yml\n",
            "Saving botprofile.yml to botprofile.yml\n",
            "Saving computers.yml to computers.yml\n",
            "Saving emotion.yml to emotion.yml\n",
            "Saving food.yml to food.yml\n",
            "Saving gossip.yml to gossip.yml\n",
            "Saving greetings.yml to greetings.yml\n",
            "Saving health.yml to health.yml\n",
            "Saving history.yml to history.yml\n",
            "Saving humor.yml to humor.yml\n",
            "Saving literature.yml to literature.yml\n",
            "Saving money.yml to money.yml\n",
            "Saving movies.yml to movies.yml\n",
            "Saving politics.yml to politics.yml\n",
            "Saving psychology.yml to psychology.yml\n",
            "Saving science.yml to science.yml\n",
            "Saving sports.yml to sports.yml\n",
            "Saving trivia.yml to trivia.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ymKMSp1Qxqd",
        "colab_type": "code",
        "outputId": "bad2ab95-1eb3-4f50-c16c-7aa1fde49376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import tensorflow as tf \n",
        "tf.test.gpu_device_name() \n",
        "# print(uploaded.items())\n",
        "# Uploading cornell dataset\n",
        "! wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-31 13:37:33--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.20\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "\r          cornell_m   0%[                    ]       0  --.-KB/s               \r         cornell_mo   2%[                    ] 232.32K  1.11MB/s               \r        cornell_mov   7%[>                   ] 730.07K  1.75MB/s               \r       cornell_movi  15%[==>                 ]   1.48M  2.42MB/s               \r      cornell_movie  27%[====>               ]   2.62M  3.21MB/s               \r     cornell_movie_  44%[=======>            ]   4.24M  4.15MB/s               \r    cornell_movie_d  66%[============>       ]   6.33M  5.16MB/s               \r   cornell_movie_di  94%[=================>  ]   8.94M  6.25MB/s               \rcornell_movie_dialo 100%[===================>]   9.46M  6.47MB/s    in 1.5s    \n",
            "\n",
            "2020-05-31 13:37:35 (6.47 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r83_F7vOfyjB",
        "colab_type": "code",
        "outputId": "33b498c8-837d-485b-f4a6-bc755b469af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "! unzip cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTz-0Im0U77n",
        "colab_type": "code",
        "outputId": "6f6a36bf-bd54-4f6c-c088-071cb6674b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import yaml\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras import preprocessing, utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJiDZU6WZQBy",
        "colab_type": "code",
        "outputId": "f61bbbc6-7f76-4a25-fd29-aa17da694db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines = open(r'/content/cornell movie-dialogs corpus/movie_lines.txt', 'r', encoding= 'latin1').read()  # convert bytes into string\n",
        "conversations = open(r'/content/cornell movie-dialogs corpus/movie_conversations.txt', 'r', encoding= 'latin1').read()\n",
        "print(type(lines))   #string"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtSn5FTBv55c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = lines.split('\\n')\n",
        "conversations = conversations.split('\\n')\n",
        "id2line = {}\n",
        "for line in lines:\n",
        "    _line = line.split(' +++$+++ ')\n",
        "    id2line[_line[0]] = _line[-1]\n",
        "\n",
        "# there aren't any errors in movie_lines file as\n",
        "# set([len(x.split(' +++$+++ ')) for x in lines]) = 5\n",
        "    \n",
        "# Creating a list of all of the conversations\n",
        "conversations_ids = []\n",
        "for conversation in conversations[:-1]:\n",
        "    _conversation = conversation.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \"\")\n",
        "    conversations_ids.append(_conversation.split(', '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE6Di5JT1sMw",
        "colab_type": "code",
        "outputId": "6723b53e-9c8d-450d-8b41-15d73b83ac93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(lines[1])\n",
        "print(conversations[0]) \n",
        "print(id2line['L100007'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
            "I'm not asking for names or specifics.  I just want to know what prompted you to make the call?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYAUee5hy0XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questions = []\n",
        "answers = []\n",
        "for conversation in conversations_ids:\n",
        "    for i in range(len(conversation) - 1):\n",
        "        questions.append(id2line[conversation[i]])\n",
        "        answers.append(id2line[conversation[i+1]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Zc9WjghbJw",
        "colab_type": "text"
      },
      "source": [
        "*Add the kaggle chatterbot dataset later on as i cant create a huge sparse matrix*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWnsJsxmzAYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "errors = []\n",
        "for x in uploaded.keys():\n",
        "  string_val = uploaded[x].decode('utf-8','ignore')\n",
        "  try:\n",
        "    ques_ans = string_val.split('\\n- - ')[1:]\n",
        "    for i in ques_ans:\n",
        "      i = i.split('\\n - ')\n",
        "      questions.append(i[0])\n",
        "      answers.append(' '.join(i[1:]))\n",
        "  except:\n",
        "    errors.append(string_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsfxksw79TJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(questions) = len(answers) = 222182"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YKaFsU88fjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "       text = text.lower()\n",
        "       text = re.sub(r\"i'm\", \"i am\", text)\n",
        "       text = re.sub(r\"he's\", \"he is\", text)\n",
        "       text = re.sub(r\"she's\", \"she is\", text)\n",
        "       text = re.sub(r\"that's\", \"that is\", text)\n",
        "       text = re.sub(r\"what's\", \"what is\", text)\n",
        "       text = re.sub(r\"where's\", \"where is\", text)\n",
        "       text = re.sub(r\"how's\", \"how is\", text)\n",
        "       text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "       text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "       text = re.sub(r\"\\'re\", \" are\", text)\n",
        "       text = re.sub(r\"\\'d\", \" would\", text)\n",
        "       text = re.sub(r\"won't\", \"will not\", text)\n",
        "       text = re.sub(r\"can't\", \"cannot\", text)\n",
        "       text = re.sub(r\"n't\", \" not\", text)\n",
        "       text = re.sub( '[^a-zA-Z]', ' ', text )\n",
        "       return text\n",
        "\n",
        "# while using tokenize punctutations are removed except ' \n",
        "# here i've tried to split most common words containing '\n",
        "for i in range(len(questions)):\n",
        "       questions[i] = clean_text(questions[i])\n",
        "       answers[i] = clean_text(answers[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PycpLgL9wz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll tokenize answers and questions\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer       \n",
        "tokenizer = Tokenizer(oov_token= 'UNK', char_level= False)\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "\n",
        "tokenizer.word_index['<SOS>'] = len(tokenizer.word_index)+1\n",
        "tokenizer.word_index['<EOS>'] = len(tokenizer.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJF1rWj5-BH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll remove too long sentences (either question or answers) as it will take un-necessary\n",
        "#memory while training\n",
        "# using counter class we find most of questions/answers <= 30 words\n",
        "req_ques = []\n",
        "req_ans = []\n",
        "for i in range(len(answers)):\n",
        "       if (len(answers[i].split()) > 30 or len(questions[i].split())> 25):\n",
        "              continue\n",
        "       else:\n",
        "              req_ans.append(answers[i])\n",
        "              req_ques.append(questions[i])\n",
        "answers = req_ans\n",
        "questions = req_ques"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBtHj0cJ-UG9",
        "colab_type": "code",
        "outputId": "dfe582cf-430b-4917-ba48-b0e73ef2dfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# len(answers) = 214627 = len(questions)\n",
        "# encoder input data\n",
        "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
        "maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
        "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen_questions , padding='post' )\n",
        "encoder_input_data = np.array( padded_questions )\n",
        "print( encoder_input_data.shape , maxlen_questions )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(190616, 25) 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0HVIR7j_BJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to add <SOS> token to decoder_input\n",
        "# Append <EOS> to decoder_target\n",
        "# since we are dealing in numbers we'll just add the required token in tokenized answers\n",
        "# texts_to_sequences cleans text before splitting into words\n",
        "\n",
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
        "decoder_input_data = [([tokenizer.word_index['<SOS>']] + tokenized_answers[i]) for i in range(len(tokenized_answers))]\n",
        "maxlen_answers = max( [ len(x) for x in decoder_input_data] )\n",
        "padded_answers = preprocessing.sequence.pad_sequences(decoder_input_data , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_input_data = np.array( padded_answers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPeIBzYr_UF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print( decoder_input_data.shape , maxlen_answers )\n",
        "# decoder_targets\n",
        "decoder_output_data = [(tokenized_answers[i]+[tokenizer.word_index['<EOS>']]) for i in range(len(tokenized_answers))]\n",
        "decoder_output_data = preprocessing.sequence.pad_sequences( decoder_output_data , maxlen=maxlen_answers , padding='post' )\n",
        "decoder_output_data = np.array(decoder_output_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af4xqvaiJVSo",
        "colab_type": "code",
        "outputId": "79f88285-7880-44ea-e1d6-cc426af2979d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "# Use glove vectors of 50d\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e703f53-78e0-48cb-a29f-f97d20843be7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8e703f53-78e0-48cb-a29f-f97d20843be7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"abhilakshmaheshwari\",\"key\":\"b4131928857e3bb171320644901f7a27\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuaTws4ZLhA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! mkdir pre_trained_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j59deusULrdO",
        "colab_type": "code",
        "outputId": "66c7a26f-3489-4b7c-9b04-d6dbbdb9a681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "! kaggle datasets download -d rtatman/glove-global-vectors-for-word-representation -p /content/pre_trained_vec\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove-global-vectors-for-word-representation.zip to /content/pre_trained_vec\n",
            "100% 457M/458M [00:04<00:00, 115MB/s]\n",
            "100% 458M/458M [00:04<00:00, 110MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwmG_ElfLzBC",
        "colab_type": "code",
        "outputId": "1fbd317d-1277-4e8c-dd99-b2f69a731e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "! unzip /content/pre_trained_vec/glove-vectors.zip -d /content/pre_trained_vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/pre_trained_vec/glove-vectors.zip\n",
            "  inflating: /content/pre_trained_vec/glove.6B.100d.txt  \n",
            "  inflating: /content/pre_trained_vec/glove.6B.200d.txt  \n",
            "  inflating: /content/pre_trained_vec/glove.6B.50d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekho0k9jL4OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove = open(r'/content/pre_trained_vec/glove.6B.50d.txt', 'r').read()\n",
        "embedding_dict = {}\n",
        "for line in glove.split('\\n')[:-1]:\n",
        "  line = line.split()\n",
        "  embedding_dict[line[0]] = np.asarray(line[1:], dtype = 'float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQUhzetbRBSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we'll create an embedding matirx which will be fed as an argument to Embedding layer\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1    # 0th index will be padding\n",
        "embedding_dim = 50\n",
        "embeddings_matrix = np.zeros((vocab_size, embedding_dim)); \n",
        "not_found_words = []\n",
        "for word,index in word_index.items():\n",
        "  vec = embedding_dict.get(word)         # if word is not present it returns None as value\n",
        "  if vec is not None:\n",
        "    embeddings_matrix[index] = vec       # words in corpus not found in glove (including oov_token) will be given 0 vector\n",
        "  else:\n",
        "    not_found_words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPLuK9tVRx98",
        "colab_type": "text"
      },
      "source": [
        "### Building model\n",
        "\n",
        "\n",
        "*   Bidirectional GRU for encoder\n",
        "*   GRU for decoder\n",
        "* Not using the faster cuDNNGRU as it doesn't support masking yet :(\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lqmW___Rwdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LATENT_DIMENSION = 128\n",
        "# Encoder\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(maxlen_questions,))\n",
        "encoder_embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen_questions, \n",
        "                                              weights=[embeddings_matrix], trainable=False,  mask_zero = True)(encoder_inputs)\n",
        "encoder_rnn = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(LATENT_DIMENSION, return_state=True, recurrent_initializer='glorot_uniform'))\n",
        "encoder_output, _,_= encoder_rnn(encoder_embedding)       # Note that size of encoder_output is (1, 2*LATENT_DIMENSION)\n",
        "                                                          # The encoder_output will act as context vector\n",
        "# Decoder\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(maxlen_answers,))\n",
        "decoder_embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen_answers, \n",
        "                                              weights=[embeddings_matrix], trainable=False, mask_zero = True)(decoder_inputs)\n",
        "decoder_rnn = tf.keras.layers.GRU(2*LATENT_DIMENSION, return_state= True, return_sequences=True)\n",
        "decoder_rnn_output, _ = decoder_rnn(decoder_embedding)\n",
        "decoder_dense = tf.keras.layers.Dense(vocab_size, activation = 'softmax') \n",
        "decoder_output = decoder_dense(decoder_rnn_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1UvwLRvRZYi",
        "colab_type": "code",
        "outputId": "8331eecd-c018-44fb-a371-7380277fd22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        }
      },
      "source": [
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_output )\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "# Visualizing the model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 31)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 31, 50)       2416450     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     [(None, 31, 256), (N 236544      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 25)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 31, 48329)    12420553    gru_1[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 15,073,547\n",
            "Trainable params: 12,657,097\n",
            "Non-trainable params: 2,416,450\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_8Y0LNl-Y-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(encoder_input_data, decoder_input_data, decoder_output_data, batch_size):\n",
        " # Create empty arrays to contain batch of features and labels#\n",
        " import random\n",
        " batch_encoder_input = np.zeros((batch_size,maxlen_questions))\n",
        " batch_decoder_input = np.zeros((batch_size,maxlen_answers))\n",
        " one_hot_targets = np.zeros((batch_size, maxlen_answers, vocab_size), dtype = 'float16')\n",
        " while True:\n",
        "   for i in range(batch_size):\n",
        "     # choose random index in features\n",
        "     index= random.sample(list(range(len(encoder_input_data))),1)\n",
        "     batch_encoder_input[i] = encoder_input_data[index]\n",
        "     batch_decoder_input[i] = decoder_input_data[index]\n",
        "     for counter,value in enumerate(decoder_output_data[index]):\n",
        "       one_hot_targets[i,counter,value] = 1\n",
        "   yield [batch_encoder_input,batch_decoder_input], one_hot_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moRMnSoA2mKq",
        "colab_type": "code",
        "outputId": "d4600a44-90e6-4f23-a8a2-4be43b545f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.fit_generator(generator(encoder_input_data, decoder_input_data, decoder_output_data, batch_size = 64),steps_per_epoch=len(encoder_input_data)//64, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2978/2978 [==============================] - 2400s 806ms/step - loss: 723.7266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f173e176400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djWDMTON-Nyc",
        "colab_type": "code",
        "outputId": "54d17b4a-3046-46ec-d94e-45eba467c64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2QnuRtyxVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chat():\n",
        "  # Cleaning input question to feed into encoder\n",
        "  seed_question = input('Enter your question: ')\n",
        "  seed_question = clean_text(seed_question)\n",
        "  seed_question = seed_question.split()\n",
        "  seed_question = tokenizer.texts_to_sequences([seed_question])\n",
        "  seed_question = preprocessing.sequence.pad_sequences(seed_question, maxlen=maxlen_questions , padding='post', truncating= 'post' )\n",
        "  seed_question = np.array(seed_question)\n",
        "\n",
        "  # Making a sampling model\n",
        "  sampling_input_encoder = tf.keras.layers.Input(shape=(maxlen_questions,))\n",
        "  sampling_encoder_embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen_questions, \n",
        "                                              weights=[embeddings_matrix], trainable=False,  mask_zero = True)(sampling_input_encoder)\n",
        "  context_vector, forward_h, backward_h = encoder_rnn(sampling_encoder_embedding)\n",
        "  encoder_model = tf.keras.models.Model(inputs = sampling_input_encoder, outputs = context_vector )\n",
        "\n",
        "  sampling_input_decoder = tf.keras.layers.Input(shape=(1,))\n",
        "  sampling_state_h_input = tf.keras.layers.Input(shape=(2*LATENT_DIMENSION,))\n",
        "  sampling_decoder_embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=1, \n",
        "                                              weights=[embeddings_matrix], trainable=False,  mask_zero = True)(sampling_input_decoder)\n",
        "  rnn_output, h = decoder_rnn(sampling_decoder_embedding, initial_state=[sampling_state_h_input])\n",
        "  sampling_output = decoder_dense(rnn_output)\n",
        "  decoder_model = tf.keras.models.Model(inputs = [sampling_input_decoder, sampling_state_h_input], outputs = [sampling_output,h] )\n",
        "  encoder_model.summary()\n",
        "  decoder_model.summary()\n",
        "  generated_text =''\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  target_seq[0][0] = word_index['<SOS>']   # SOS token\n",
        "  initial_h = encoder_model.predict([seed_question])\n",
        "  for _ in range(maxlen_answers):\n",
        "    prob,initial_h = decoder_model.predict([target_seq, initial_h])\n",
        "    next_word_index = np.argmax(prob)\n",
        "    if (next_word_index == word_index['<EOS>'] or next_word_index == 0):\n",
        "      break\n",
        "    else:\n",
        "      generated_text += ' '+rev_index_word[next_word_index]\n",
        "      target_seq[0][0] = next_word_index\n",
        "  return generated_text\n",
        "      \n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9alkbdoLU9eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rev_index_word = {i:u for i, u in enumerate(tokenizer.word_index.keys())}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxN9ZV4ZWVFT",
        "colab_type": "code",
        "outputId": "8e157f3a-a411-442b-9865-c44d5c78947a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "chat()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your question: What is a computer\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 25)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 25, 50)            2416450   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional [(None, 256), (None, 128) 138240    \n",
            "=================================================================\n",
            "Total params: 2,554,690\n",
            "Trainable params: 138,240\n",
            "Non-trainable params: 2,416,450\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 50)        2416450     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     multiple             236544      embedding_6[0][0]                \n",
            "                                                                 input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   multiple             12420553    gru_1[2][0]                      \n",
            "==================================================================================================\n",
            "Total params: 15,073,547\n",
            "Trainable params: 12,657,097\n",
            "Non-trainable params: 2,416,450\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' until hours understand the late mother ask seems understand seems understand seems understand seems understand seems understand seems understand seems understand seems understand seems understand seems understand seems understand seems understand'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmKfMPDHZSaS",
        "colab_type": "code",
        "outputId": "7c3681f2-516e-43e8-f4d9-98cf3c21ed88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# Downloading the model\n",
        "!zip -r /content/trained_chatbot_model.zip /content/saved_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/saved_model/ (stored 0%)\n",
            "  adding: content/saved_model/my_model/ (stored 0%)\n",
            "  adding: content/saved_model/my_model/saved_model.pb (deflated 89%)\n",
            "  adding: content/saved_model/my_model/assets/ (stored 0%)\n",
            "  adding: content/saved_model/my_model/variables/ (stored 0%)\n",
            "  adding: content/saved_model/my_model/variables/variables.index (deflated 59%)\n",
            "  adding: content/saved_model/my_model/variables/variables.data-00000-of-00002 (deflated 21%)\n",
            "  adding: content/saved_model/my_model/variables/variables.data-00001-of-00002 (deflated 18%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}